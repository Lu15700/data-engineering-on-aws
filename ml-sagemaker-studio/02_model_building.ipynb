{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e749dcc7-88cd-49f3-89ce-c94e8c7bbc21",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Collaborative Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1837007e-0773-43c6-bdd1-b768addd31b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker_datawrangler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7f6369-dfd3-4158-8f9f-b0f5ea929a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Parquet from S3 locally, or use awswrangler to read pandas df directly from S3\n",
    "no2_file = \"YOUR-FILE-LOCATION\"\n",
    "weather_file = \"YOUR-FILE-LOCATION\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8f0dec9-35ed-44f3-a9ac-c4c37b80eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no2 = pd.read_parquet(no2_file)\n",
    "df_weather = pd.read_parquet(weather_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abbf8dd9-93a9-4ddb-b21c-f8a404b3792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf939f7-fb1e-4129-8ad4-0c9103ef41b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas code generated by sagemaker_datawrangler\n",
    "output_df = df_weather.copy(deep=True)\n",
    "\n",
    "\n",
    "# Code to Replace with median for column: visibility to resolve warning: Missing values \n",
    "output_df['visibility']=output_df['visibility'].fillna(output_df['visibility'].median(skipna=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3de8be06-03c1-418c-9991-14b01b7501bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no2['ymd'] = pd.to_datetime(df_no2['ymd'], infer_datetime_format=True)\n",
    "df_no2 = df_no2.set_index('ymd')\n",
    "\n",
    "idx = pd.date_range(df_no2.index.min(), df_no2.index.max())\n",
    "df_no2 = df_no2.reindex(idx, fill_value=None)\n",
    "df_no2 = df_no2.interpolate(method='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4a08b72-d20f-41f5-91bd-f9d5ec279c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df['date'] = pd.to_datetime(output_df['date'], infer_datetime_format=True)\n",
    "output_df = output_df.set_index('date').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52f3113d-ce9c-45b1-af33-0db9c2f40964",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_viable_date = max(df_no2.index.min(), output_df.index.min())\n",
    "max_viable_date = min(df_no2.index.max(), output_df.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03cf96ed-3f7e-4466-97d7-aa1aea153a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging dataframes between 2016-03-06 00:00:00 and 2022-11-14 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(f\"Merging dataframes between {min_viable_date} and {max_viable_date}\")\n",
    "\n",
    "comp_df = pd.merge(\n",
    "    output_df[min_viable_date:max_viable_date],\n",
    "    df_no2[min_viable_date:max_viable_date][['no2_avg']],\n",
    "    left_index=True, right_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "746e2db9-d62e-4e6a-b5d6-79f0d2e85e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = comp_df[['wind_avg','no2_avg']]\n",
    "\n",
    "x = mydata['wind_avg']\n",
    "y = mydata['no2_avg']\n",
    "plt.scatter(x, y)\n",
    "\n",
    "z = np.polyfit(x, y, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(x,p(x),\"r--\")\n",
    "\n",
    "plt.ylabel('NO2 Conc. ppm')\n",
    "plt.xlabel('Wind Speed (mph)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3beb531-1728-445f-a682-05b936f08b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 1st row as NaN\n",
    "aq_df = comp_df.iloc[1:].copy()\n",
    "\n",
    "# Drop visibility as it didn't seem correlate much and has NaNs that break the training\n",
    "aq_df = aq_df.drop('visibility', 1)\n",
    "\n",
    "# Use the data from years 2016 up to 2020 as training, and the year 2021 as our candidate year for testing and validating our model.\n",
    "aq_train_df = aq_df[aq_df.index.year < 2021]\n",
    "aq_test_df = aq_df[aq_df.index.year == 2021]\n",
    "\n",
    "x_train_df = aq_train_df.drop('no2_avg',1)\n",
    "x_train = x_train_df.values.astype('float32')\n",
    "\n",
    "\n",
    "x_test_df = aq_test_df.drop('no2_avg',1)\n",
    "x_test = x_test_df.values.astype('float32')\n",
    "\n",
    "y_train_df = aq_train_df[[\"no2_avg\"]]\n",
    "y_train = y_train_df.values[:, 0].astype('float32')\n",
    "\n",
    "y_test_df = aq_test_df[[\"no2_avg\"]]\n",
    "y_test = y_test_df.values[:, 0].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbc3accb-ff40-4ed8-9f98-aa369cb8c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "\n",
    "def smape(actual, predicted):\n",
    "    dividend= np.abs(np.array(actual) - np.array(predicted))\n",
    "    denominator = np.array(actual) + np.array(predicted)\n",
    "    \n",
    "    return 2 * np.mean(np.divide(dividend, denominator, out=np.zeros_like(dividend), where=denominator!=0, casting='unsafe'))\n",
    "\n",
    "def print_metrics(y_test, y_pred):\n",
    "    print(\"RMSE: %.4f\" % sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    print('Variance score: %.4f' % r2_score(y_test, y_pred))\n",
    "    print('Explained variance score: %.4f' % explained_variance_score(y_test, y_pred))\n",
    "    forecast_err = np.array(y_test) - np.array(y_pred)\n",
    "    print('Forecast bias: %.4f' % (np.sum(forecast_err) * 1.0/len(y_pred) ))\n",
    "    print('sMAPE: %.4f' % smape(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3f9a0f2-5425-4322-85f6-6cbff7a1d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b61dc1a6-1227-4fa9-aa9c-b12aa64d48d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "reg = RandomForestRegressor(max_depth=4)\n",
    "reg.fit(x_train, y_train)\n",
    "reg.score(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f6fc3e-9d21-4fe1-a502-0e748737c87f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Real Time Collaboration - Model Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066f22bd-153f-485e-890e-c5f14d376ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# reg = RandomForestRegressor(max_depth=4)\n",
    "# reg.fit(x_train, y_train)\n",
    "# reg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6a1f85-3dd8-4fd3-bc09-9058b8c0b9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = reg.predict(x_test)\n",
    "print_metrics(y_test, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd38233-9e94-4176-922d-ec38d5fa7861",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df = pd.DataFrame(result, columns=y_test_df.columns).set_index(y_test_df.index).sort_index()\n",
    "\n",
    "plt.plot(y_test_df, label='actual')\n",
    "plt.plot(y_pred_df, label='forecast')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304d2f2c-0ae1-4b83-8e8c-831918079f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save model\n",
    "joblib.dump(reg, \"data/model.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b3fb06bf-1c6a-4414-968a-7f8f4068ff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to S3\n",
    "!aws s3 cp data/model.pkl s3://YOUR-S3-BUCKET/airquality-experiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c9c838-85d9-45ef-b38e-6d5d10e70aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
